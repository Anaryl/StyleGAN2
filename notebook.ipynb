{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from math import log2, sqrt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Hyperparameters\n",
    "\n",
    "DATASET = \"Women clothes\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "EPOCHS = 300\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 32\n",
    "LOG_RESOLUTION = 7 #for 128*128\n",
    "Z_DIM = 256\n",
    "W_DIM = 256\n",
    "LAMBDA_GP = 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helpers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_loader():\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((2 ** LOG_RESOLUTION, 2 ** LOG_RESOLUTION)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.Normalize(\n",
    "                [0.5, 0.5, 0.5],\n",
    "                [0.5, 0.5, 0.5],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    dataset = datasets.ImageFolder(root=DATASET, transform=transform)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    return loader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Noise mapping network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class MappingNetwork(nn.Module):\n",
    "    def __init__(self, z_dim, w_dim):\n",
    "        super().__init__()\n",
    "        self.mapping = nn.Sequential(\n",
    "            EqualizedLinear(z_dim, w_dim),\n",
    "            nn.ReLU(),\n",
    "            EqualizedLinear(z_dim, w_dim),\n",
    "            nn.ReLU(),\n",
    "            EqualizedLinear(z_dim, w_dim),\n",
    "            nn.ReLU(),\n",
    "            EqualizedLinear(z_dim, w_dim),\n",
    "            nn.ReLU(),\n",
    "            EqualizedLinear(z_dim, w_dim),\n",
    "            nn.ReLU(),\n",
    "            EqualizedLinear(z_dim, w_dim),\n",
    "            nn.ReLU(),\n",
    "            EqualizedLinear(z_dim, w_dim),\n",
    "            nn.ReLU(),\n",
    "            EqualizedLinear(z_dim, w_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "    \t  x = x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + 1e-8)  # for PixelNorm \n",
    "        return self.mapping(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generator class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, log_resolution, W_DIM, n_features = 32, max_features = 256):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        features = [min(max_features, n_features * (2 ** i)) for i in range(log_resolution - 2, -1, -1)]\n",
    "        self.n_blocks = len(features)\n",
    "\n",
    "        self.initial_constant = nn.Parameter(torch.randn((1, features[0], 4, 4)))\n",
    "\n",
    "        self.style_block = StyleBlock(W_DIM, features[0], features[0])\n",
    "        self.to_rgb = ToRGB(W_DIM, features[0])\n",
    "\n",
    "        blocks = [GeneratorBlock(W_DIM, features[i - 1], features[i]) for i in range(1, self.n_blocks)]\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "    def forward(self, w, input_noise):\n",
    "\n",
    "        batch_size = w.shape[1]\n",
    "\n",
    "        x = self.initial_constant.expand(batch_size, -1, -1, -1)\n",
    "        x = self.style_block(x, w[0], input_noise[0][1])\n",
    "        rgb = self.to_rgb(x, w[0])\n",
    "\n",
    "        for i in range(1, self.n_blocks):\n",
    "            x = F.interpolate(x, scale_factor=2, mode=\"bilinear\")\n",
    "            x, rgb_new = self.blocks[i - 1](x, w[i], input_noise[i])\n",
    "            rgb = F.interpolate(rgb, scale_factor=2, mode=\"bilinear\") + rgb_new\n",
    "\n",
    "        return torch.tanh(rgb)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generator  block class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class GeneratorBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, W_DIM, in_features, out_features):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.style_block1 = StyleBlock(W_DIM, in_features, out_features)\n",
    "        self.style_block2 = StyleBlock(W_DIM, out_features, out_features)\n",
    "\n",
    "        self.to_rgb = ToRGB(W_DIM, out_features)\n",
    "\n",
    "    def forward(self, x, w, noise):\n",
    "\n",
    "        x = self.style_block1(x, w, noise[0])\n",
    "        x = self.style_block2(x, w, noise[1])\n",
    "\n",
    "        rgb = self.to_rgb(x, w)\n",
    "\n",
    "        return x, rgb\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Style block class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class StyleBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, W_DIM, in_features, out_features):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.to_style = EqualizedLinear(W_DIM, in_features, bias=1.0)\n",
    "        self.conv = Conv2dWeightModulate(in_features, out_features, kernel_size=3)\n",
    "        self.scale_noise = nn.Parameter(torch.zeros(1))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "\n",
    "        self.activation = nn.LeakyReLU(0.2, True)\n",
    "\n",
    "    def forward(self, x, w, noise):\n",
    "\n",
    "        s = self.to_style(w)\n",
    "        x = self.conv(x, s)\n",
    "        if noise is not None:\n",
    "            x = x + self.scale_noise[None, :, None, None] * noise\n",
    "        return self.activation(x + self.bias[None, :, None, None])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert to RGB class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ToRGB(nn.Module):\n",
    "\n",
    "    def __init__(self, W_DIM, features):\n",
    "\n",
    "        super().__init__()\n",
    "        self.to_style = EqualizedLinear(W_DIM, features, bias=1.0)\n",
    "\n",
    "        self.conv = Conv2dWeightModulate(features, 3, kernel_size=1, demodulate=False)\n",
    "        self.bias = nn.Parameter(torch.zeros(3))\n",
    "        self.activation = nn.LeakyReLU(0.2, True)\n",
    "\n",
    "    def forward(self, x, w):\n",
    "\n",
    "        style = self.to_style(w)\n",
    "        x = self.conv(x, style)\n",
    "        return self.activation(x + self.bias[None, :, None, None])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolution with Weight Modulation and Demodulation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Conv2dWeightModulate(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, kernel_size,\n",
    "                 demodulate = True, eps = 1e-8):\n",
    "\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "        self.demodulate = demodulate\n",
    "        self.padding = (kernel_size - 1) // 2\n",
    "\n",
    "        self.weight = EqualizedWeight([out_features, in_features, kernel_size, kernel_size])\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, s):\n",
    "\n",
    "        b, _, h, w = x.shape\n",
    "\n",
    "        s = s[:, None, :, None, None]\n",
    "        weights = self.weight()[None, :, :, :, :]\n",
    "        weights = weights * s\n",
    "\n",
    "        if self.demodulate:\n",
    "            sigma_inv = torch.rsqrt((weights ** 2).sum(dim=(2, 3, 4), keepdim=True) + self.eps)\n",
    "            weights = weights * sigma_inv\n",
    "\n",
    "        x = x.reshape(1, -1, h, w)\n",
    "\n",
    "        _, _, *ws = weights.shape\n",
    "        weights = weights.reshape(b * self.out_features, *ws)\n",
    "\n",
    "        x = F.conv2d(x, weights, padding=self.padding, groups=b)\n",
    "\n",
    "        return x.reshape(-1, self.out_features, h, w)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discriminator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, log_resolution, n_features = 64, max_features = 256):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        features = [min(max_features, n_features * (2 ** i)) for i in range(log_resolution - 1)]\n",
    "\n",
    "        self.from_rgb = nn.Sequential(\n",
    "            EqualizedConv2d(3, n_features, 1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "        )\n",
    "        n_blocks = len(features) - 1\n",
    "        blocks = [DiscriminatorBlock(features[i], features[i + 1]) for i in range(n_blocks)]\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "        final_features = features[-1] + 1\n",
    "        self.conv = EqualizedConv2d(final_features, final_features, 3)\n",
    "        self.final = EqualizedLinear(2 * 2 * final_features, 1)\n",
    "\n",
    "    def minibatch_std(self, x):\n",
    "        batch_statistics = (\n",
    "            torch.std(x, dim=0).mean().repeat(x.shape[0], 1, x.shape[2], x.shape[3])\n",
    "        )\n",
    "        return torch.cat([x, batch_statistics], dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.from_rgb(x)\n",
    "        x = self.blocks(x)\n",
    "\n",
    "        x = self.minibatch_std(x)\n",
    "        x = self.conv(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        return self.final(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discriminator block class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DiscriminatorBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.residual = nn.Sequential(nn.AvgPool2d(kernel_size=2, stride=2), # down sampling using avg pool\n",
    "                                      EqualizedConv2d(in_features, out_features, kernel_size=1))\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            EqualizedConv2d(in_features, in_features, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            EqualizedConv2d(in_features, out_features, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "        )\n",
    "\n",
    "        self.down_sample = nn.AvgPool2d(\n",
    "            kernel_size=2, stride=2\n",
    "        )  # down sampling using avg pool\n",
    "\n",
    "        self.scale = 1 / sqrt(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "\n",
    "        x = self.block(x)\n",
    "        x = self.down_sample(x)\n",
    "\n",
    "        return (x + residual) * self.scale"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learning-rate Equalized Linear Layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class EqualizedLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias = 0.):\n",
    "\n",
    "        super().__init__()\n",
    "        self.weight = EqualizedWeight([out_features, in_features])\n",
    "        self.bias = nn.Parameter(torch.ones(out_features) * bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return F.linear(x, self.weight(), bias=self.bias)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learning-rate Equalized 2D Convolution Layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class EqualizedConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features,\n",
    "                 kernel_size, padding = 0):\n",
    "\n",
    "        super().__init__()\n",
    "        self.padding = padding\n",
    "        self.weight = EqualizedWeight([out_features, in_features, kernel_size, kernel_size])\n",
    "        self.bias = nn.Parameter(torch.ones(out_features))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return F.conv2d(x, self.weight(), bias=self.bias, padding=self.padding)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learning-rate Equalized Weights Parameter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class EqualizedWeight(nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.c = 1 / sqrt(np.prod(shape[1:]))\n",
    "        self.weight = nn.Parameter(torch.randn(shape))\n",
    "\n",
    "    def forward(self):\n",
    "        return self.weight * self.c"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perceptual path length normalization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class PathLengthPenalty(nn.Module):\n",
    "\n",
    "    def __init__(self, beta):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.beta = beta\n",
    "        self.steps = nn.Parameter(torch.tensor(0.), requires_grad=False)\n",
    "\n",
    "        self.exp_sum_a = nn.Parameter(torch.tensor(0.), requires_grad=False)\n",
    "\n",
    "    def forward(self, w, x):\n",
    "\n",
    "        device = x.device\n",
    "        image_size = x.shape[2] * x.shape[3]\n",
    "        y = torch.randn(x.shape, device=device)\n",
    "\n",
    "        output = (x * y).sum() / sqrt(image_size)\n",
    "        sqrt(image_size)\n",
    "\n",
    "        gradients, *_ = torch.autograd.grad(outputs=output,\n",
    "                                            inputs=w,\n",
    "                                            grad_outputs=torch.ones(output.shape, device=device),\n",
    "                                            create_graph=True)\n",
    "\n",
    "        norm = (gradients ** 2).sum(dim=2).mean(dim=1).sqrt()\n",
    "\n",
    "        if self.steps > 0:\n",
    "\n",
    "            a = self.exp_sum_a / (1 - self.beta ** self.steps)\n",
    "\n",
    "            loss = torch.mean((norm - a) ** 2)\n",
    "        else:\n",
    "            loss = norm.new_tensor(0)\n",
    "\n",
    "        mean = norm.mean().detach()\n",
    "        self.exp_sum_a.mul_(self.beta).add_(mean, alpha=1 - self.beta)\n",
    "        self.steps.add_(1.)\n",
    "\n",
    "        return loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utils \n",
    "Gradient penalty"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def gradient_penalty(critic, real, fake,device=\"cpu\"):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    beta = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * beta + fake.detach() * (1 - beta)\n",
    "    interpolated_images.requires_grad_(True)\n",
    "\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images)\n",
    " \n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_w(batch_size):\n",
    "\n",
    "    z = torch.randn(batch_size, W_DIM).to(DEVICE)\n",
    "    w = mapping_network(z)\n",
    "    return w[None, :, :].expand(LOG_RESOLUTION, -1, -1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_noise(batch_size):\n",
    "    \n",
    "        noise = []\n",
    "        resolution = 4\n",
    "\n",
    "        for i in range(LOG_RESOLUTION):\n",
    "            if i == 0:\n",
    "                n1 = None\n",
    "            else:\n",
    "                n1 = torch.randn(batch_size, 1, resolution, resolution, device=DEVICE)\n",
    "            n2 = torch.randn(batch_size, 1, resolution, resolution, device=DEVICE)\n",
    "\n",
    "            noise.append((n1, n2))\n",
    "\n",
    "            resolution *= 2\n",
    "\n",
    "        return noise"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def generate_examples(gen, epoch, n=100):\n",
    "    \n",
    "    gen.eval()\n",
    "    alpha = 1.0\n",
    "    for i in range(n):\n",
    "        with torch.no_grad():\n",
    "            w     = get_w(1)\n",
    "            noise = get_noise(1)\n",
    "            img = gen(w, noise)\n",
    "            if not os.path.exists(f'saved_examples/epoch{epoch}'):\n",
    "                os.makedirs(f'saved_examples/epoch{epoch}')\n",
    "            save_image(img*0.5+0.5, f\"saved_examples/epoch{epoch}/img_{i}.png\")\n",
    "\n",
    "    gen.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_fn(\n",
    "    critic,\n",
    "    gen,\n",
    "    path_length_penalty,\n",
    "    loader,\n",
    "    opt_critic,\n",
    "    opt_gen,\n",
    "    opt_mapping_network,\n",
    "):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "\n",
    "    for batch_idx, (real, _) in enumerate(loop):\n",
    "        real = real.to(DEVICE)\n",
    "        cur_batch_size = real.shape[0]\n",
    "\n",
    "        w     = get_w(cur_batch_size)\n",
    "        noise = get_noise(cur_batch_size)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            fake = gen(w, noise)\n",
    "            critic_fake = critic(fake.detach())\n",
    "            \n",
    "            critic_real = critic(real)\n",
    "            gp = gradient_penalty(critic, real, fake, device=DEVICE)\n",
    "            loss_critic = (\n",
    "                -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
    "                + LAMBDA_GP * gp\n",
    "                + (0.001 * torch.mean(critic_real ** 2))\n",
    "            )\n",
    "\n",
    "        critic.zero_grad()\n",
    "        loss_critic.backward()\n",
    "        opt_critic.step()\n",
    "\n",
    "        gen_fake = critic(fake)\n",
    "        loss_gen = -torch.mean(gen_fake)\n",
    "\n",
    "        if batch_idx % 16 == 0:\n",
    "            plp = path_length_penalty(w, fake)\n",
    "            if not torch.isnan(plp):\n",
    "                loss_gen = loss_gen + plp\n",
    "\n",
    "        mapping_network.zero_grad()\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "        opt_mapping_network.step()\n",
    "\n",
    "        loop.set_postfix(\n",
    "            gp=gp.item(),\n",
    "            loss_critic=loss_critic.item(),\n",
    "        )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loader = get_loader()\n",
    "\n",
    "gen = Generator(LOG_RESOLUTION, W_DIM).to(DEVICE)\n",
    "critic = Discriminator(LOG_RESOLUTION).to(DEVICE)\n",
    "mapping_network = MappingNetwork(Z_DIM, W_DIM).to(DEVICE)\n",
    "path_length_penalty = PathLengthPenalty(0.99).to(DEVICE)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.99))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.99))\n",
    "opt_mapping_network = optim.Adam(mapping_network.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.99))\n",
    "\n",
    "gen.train()\n",
    "critic.train()\n",
    "mapping_network.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loader = get_loader()  \n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_fn(\n",
    "        critic,\n",
    "        gen,\n",
    "        path_length_penalty,\n",
    "        loader,\n",
    "        opt_critic,\n",
    "        opt_gen,\n",
    "        opt_mapping_network,\n",
    "    )\n",
    "    if epoch % 50 == 0:\n",
    "    \tgenerate_examples(gen, epoch)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}